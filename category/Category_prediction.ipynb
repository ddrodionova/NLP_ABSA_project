{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "9r7ATJD7zHkG",
    "outputId": "40f41d19-bffd-4d98-deae-affbd5bdfa71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages)\u001b[0m\n",
      "Collecting python-crfsuite\n",
      "  Downloading python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n",
      "\u001b[K     |████████████████████████████████| 743 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: python-crfsuite\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages)\u001b[0m\n",
      "Successfully installed python-crfsuite-0.9.7\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/marynepo/anaconda3/envs/py37/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install python-crfsuite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "699238be"
   },
   "source": [
    "# Чтение файлов с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "54064900512946a19040cca9a7b82e68",
      "79453b158d684585a15ada1fa853caba",
      "e0fdf9b289a847f5b1a150faacc20ade",
      "8531cde142584324b212b7a509f47be4",
      "58557af4f4324953ab21ebf6a6bae77c",
      "d31990b02c4d40c2961776b303a7fb0d",
      "1772388bcbb9481596c7f61c4b57a319",
      "d397546a7708495c929a68b786586779",
      "ac5e7c14666f476e802cca24bd1ca59e",
      "81db27d8ef1842509c248b404849d436",
      "7024e1a9fc0e4d3a8c78f191f2f3d926",
      "d7658cd04b984486af4cde6763fbe847",
      "32c26bce5567415cac8dcf9ff296bcbc",
      "7dddf865418f45cd8ad98b89e2dcd5ab",
      "652b46a7dbef47aca6032f67a1c98256",
      "5b5ced37b48c4a2480ce9c327eb6e2d7",
      "a394d8b703a14a759f33d9eee8dc8c5a",
      "5ebb4cb43ba34eea92fdb030cf7f6afd",
      "5fd9bbd673344886840007fdd22ad0c0",
      "24e1ddb189c241efb10fe2ae09ff6f96",
      "3b7b7d270cbc44da92974d964cd14fc5",
      "ae430dfc37294e588bb1301b81aabfa6"
     ]
    },
    "collapsed": true,
    "id": "95c38abc",
    "outputId": "fcbe2744-426b-4cc8-bf28-73fb4ba601d7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9cf03159a494329b2b391efacfe4f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading https://raw.githubusercontent.com/stanfordnlp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-27 02:53:46 INFO: Downloading default packages for language: ru (Russian)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-27 02:53:49 INFO: File exists: /home/marynepo/stanza_resources/ru/default.zip.\n",
      "2021-12-27 02:53:59 INFO: Finished downloading models and saved to /home/marynepo/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import stanza\n",
    "stanza.download('ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8166f5e6",
    "outputId": "a907a2eb-72a2-4dc4-b7d1-f7de0d4f2903"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "train_asp = pd.read_csv(\n",
    "    'train_split_aspects.txt', \n",
    "    delimiter='\\t', \n",
    "    names=['text_id', 'category', 'mention', 'start', 'end', 'sentiment']\n",
    ")\n",
    "train_texts = pd.read_csv('train_split_reviews.txt', delimiter='\\t', names=['text_id','text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2c0e2817"
   },
   "source": [
    "# Baseline 1: категория упоминаний\n",
    "\n",
    "Основной способ, которым мы пользуемся - crf (через pycrfsuite). Для этого делаем bio-разметку данных.\n",
    "Признаки слов, которые подаем на вход в crf: лемма, часть речи, регистр (istitle, islower, issuper) самого слова и его соседей справа и слева.\n",
    "\n",
    "Эксперименты:\n",
    "\n",
    "1) Добавление tfidf и word2vec (ruscorpora_mystem_cbow_300_2_2015.bin.gz) в признаки (смотрим вектора лемм, а не самих слов). Результат практически не изменился (возможно, их надо подавать по-другому, но не нашли как, или эта модель не предназначена для обучения на них).\n",
    "\n",
    "2) Изменение алгоритмов crf (lbfgs, l2sgd, ap, pa, arow). Дают похожие результаты, лучше всего работают lbfgs, l2sgd  (и у pa лучшая полнота, но хуже все остальное). Неплохие точность и accuracy, хуже всего показатели полноты. Поэтому пробуем добавить информацию из словарей (пункт 3). \n",
    "\n",
    "3) Добавление информации из словарей. Составляем правила с помощью yargy и добавляем то, что он извлек, к результатам crf. В результате для всех алгоритмов полнота действительно возрастает на 0.3-0.5, но ожидаемо падают точность и accuracy. \n",
    "\n",
    "Датасеты, которые для этого использовались:\n",
    "\n",
    "1) Датасет со списом заведений общественного питания Москвы от правительства Москвы 2015 г.. Из него брались названия заведений и их тип для категории Whole. Давал совсем плохие результаты на yargy, поэтому не использовался в дальнейшем. [cafes.csv]() [Источник](https://data.gov.ru/opendata/7710881420-obshchestvennoe)\n",
    "\n",
    "2) Датасет с 147000 рецептами с сайта povarenok.ru. Использовалась только колонка с ингредиентами (брались названия продуктов), поскольку названия блюд были слишком длинные и их нужно было дополнительно парсить, но при попытке выделить NP из них с помощью yargy компьютер зависал и падал. [recipes.csv]() [Источник](https://www.kaggle.com/rogozinushka/povarenok-recipes)\n",
    "\n",
    "3) Семантический датасет от КартыСлов (есть набор слов, где каждому соответсутвует тег какой-то семантической категории). Брались слова с тегами FOOD (для категории Food) и CONSTRUCTION (для категории Interior, поскольку там встречалась мебель) [semantic_simple.csv]() [Источник](https://raw.githubusercontent.com/dkulagin/kartaslov/master/dataset/open_semantics/simple/semantics_simple.csv)\n",
    "\n",
    "Результаты хранятся в файлах вида pred_asp.csv (без всего), pred_asp_arg.csv (векторы+алгоритмы) и pred_asp_arg_dict.csv (векторы+алгоритмы+словари), где вместо arg -  название алгоритм.\n",
    "\n",
    "Лучшие результаты по заданным метрикам (pred_asp_lbfgs):\n",
    "\n",
    "Full match precision: 0.7906724511930586\n",
    "Full match recall: 0.6126050420168068\n",
    "Partial match ratio in pred: 0.8893709327548807\n",
    "Full category accuracy: 0.7657266811279827\n",
    "Partial category accuracy: 0.8828633405639913\n",
    "\n",
    "Судя по этим метрикам + по другим метрикам для crf, самые большие проблемы возникают с аспектами, в которых больше 1 токена, плохо предсказываются I- теги."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e55fqJMD2FEU"
   },
   "source": [
    "### Yargy и словари."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VgGIcR8hWJCh"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('cafes.json') as f:\n",
    "    cafes = json.load(f)\n",
    "\n",
    "cafes = pd.json_normalize(cafes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "names = set()\n",
    "for name in cafes['Name'].values:\n",
    "    if re.search('«.+»', name):\n",
    "        names.add(re.search('«(.+)»', name).group(1).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yargy import rule, Parser, or_, and_\n",
    "from yargy.predicates import eq\n",
    "from yargy.predicates import gte, lte, caseless, normalized, dictionary, gram, is_capitalized\n",
    "from yargy.pipelines import morph_pipeline\n",
    "\n",
    "'''NP = rule(\n",
    "    gram('ADJF').optional().repeatable(),\n",
    "    gram('NOUN'),\n",
    "    dictionary('и').optional(),\n",
    "    gram('NOUN').optional(),\n",
    "    dictionary('c').optional(),\n",
    "    gram('NOUN').optional(),\n",
    ")'''\n",
    "\n",
    "CAFE_TYPE = dictionary(set(cafes['TypeObject'].values))\n",
    "\n",
    "CAFE_NAMES = dictionary(names)\n",
    "\n",
    "#WHOLE = rule(CAFE_TYPE.optional(), eq('\"').optional(), and_(CAFE_NAMES, is_capitalized()), eq('\"').optional())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "LxGd2O_XucM-"
   },
   "outputs": [],
   "source": [
    "recipes = pd.read_csv('recipes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "fUHoUL0SwZEE",
    "outputId": "8f502353-2174-4b0c-bc7b-7506540a7040"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "ingrs = set()\n",
    "\n",
    "for ing in recipes['ingredients'].values:\n",
    "    try:\n",
    "        for k in ast.literal_eval(ing).keys():\n",
    "            ingrs.add(k.lower())\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eeOSQ8CH8afM",
    "outputId": "d941beff-d698-489e-8f81-d8d2ee78c7b9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-27 03:45:07--  https://raw.githubusercontent.com/dkulagin/kartaslov/master/dataset/open_semantics/simple/semantics_simple.csv\n",
      "Распознаётся raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Подключение к raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа... 200 OK\n",
      "Длина: 1123450 (1,1M) [text/plain]\n",
      "Сохранение в каталог: ««semantics_simple.csv.2»».\n",
      "\n",
      "semantics_simple.cs 100%[===================>]   1,07M  1,67MB/s    in 0,6s    \n",
      "\n",
      "2021-12-27 03:45:08 (1,67 MB/s) - «semantics_simple.csv.2» сохранён [1123450/1123450]\n",
      "\n",
      "--2021-12-27 03:45:08--  http://semantics_simple.csv/\n",
      "Распознаётся semantics_simple.csv (semantics_simple.csv)... ошибка: Имя или служба не известны.\n",
      "wget: не удаётся разрешить адрес «semantics_simple.csv»\n",
      "ЗАВЕРШЕНО --2021-12-27 03:45:08--\n",
      "Общее время: 1,2s\n",
      "Загружено: 1 файлов, 1,1M за 0,6s (1,67 MB/s)\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/dkulagin/kartaslov/master/dataset/open_semantics/simple/semantics_simple.csv semantics_simple.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "znQFiqYs8jSi"
   },
   "outputs": [],
   "source": [
    "semsim = pd.read_csv('semantics_simple.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ABSTRACT',\n",
       " 'ABSTRACT:ACTION',\n",
       " 'ANATOMY',\n",
       " 'ANIMAL',\n",
       " 'CONSTRUCTION',\n",
       " 'FOOD',\n",
       " 'HUMAN',\n",
       " 'PLACE',\n",
       " 'PLANT',\n",
       " 'SUBSTANCE',\n",
       " 'THING',\n",
       " 'TRANSPORT'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(semsim['tag'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DczAsHCe9n8f",
    "outputId": "7fb901a6-bf95-4aa2-c105-ad1b4e77947a"
   },
   "outputs": [],
   "source": [
    "FOOD_N = rule(dictionary(set(semsim['term'][semsim['tag'] == 'FOOD'].values).union(ingrs)))\n",
    "INTERIOR = rule(dictionary(set(semsim['term'][semsim['tag'] == 'CONSTRUCTION'].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_matches(r, t):\n",
    "    parser = Parser(r)\n",
    "    res = []\n",
    "    for match in parser.findall(t):\n",
    "        start, end = match.span\n",
    "        res.append((t[start:end], start, end))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_asp = pd.read_csv(\n",
    "    'dev_aspects.txt', \n",
    "    delimiter='\\t', \n",
    "    names=['text_id', 'category', 'mention', 'start', 'end', 'sentiment']\n",
    ")\n",
    "test_texts = pd.read_csv('dev_reviews.txt', delimiter='\\t', names=['text_id','text'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:26<00:00,  2.71it/s]\n"
     ]
    }
   ],
   "source": [
    "foods = []\n",
    "wholes = []\n",
    "intrs = []\n",
    "for text in tqdm(test_texts['text'].values):\n",
    "    foods.append(rule_matches(FOOD_N, text))\n",
    "    wholes.append(rule_matches(WHOLE, text))\n",
    "    intrs.append(rule_matches(INTERIOR, text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторайзеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "LBFfNvLvQYoq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ruscorpora_mystem_cbow_300_2_2015.bin.gz',\n",
       " <http.client.HTTPMessage at 0x7f02a26ebd90>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "\n",
    "urllib.request.urlretrieve(\"http://rusvectores.org/static/models/rusvectores2/ruscorpora_mystem_cbow_300_2_2015.bin.gz\", \"ruscorpora_mystem_cbow_300_2_2015.bin.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2dc17642"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "m = 'ruscorpora_mystem_cbow_300_2_2015.bin.gz'\n",
    "\n",
    "if m.endswith('.vec.gz'):\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=False)\n",
    "elif m.endswith('.bin.gz'):\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=True)\n",
    "else:\n",
    "    model = gensim.models.KeyedVectors.load(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-27 02:58:03 INFO: Loading these models for language: ru (Russian):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | syntagrus |\n",
      "| pos       | syntagrus |\n",
      "| lemma     | syntagrus |\n",
      "=========================\n",
      "\n",
      "2021-12-27 02:58:03 INFO: Use device: cpu\n",
      "2021-12-27 02:58:03 INFO: Loading: tokenize\n",
      "2021-12-27 02:58:03 INFO: Loading: pos\n",
      "2021-12-27 02:58:04 INFO: Loading: lemma\n",
      "2021-12-27 02:58:04 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "nlp = stanza.Pipeline('ru', processors='tokenize, pos, lemma')\n",
    "\n",
    "def normalize(text):\n",
    "    doc = nlp(text)\n",
    "    words = [word.lemma for sent in doc.sentences for word in sent.words if word.pos != 'PUNCT']\n",
    "    return ' '.join(words)\n",
    "corpus = [normalize(text) for text in train_texts['text'].values]\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oSVOvk77EifS",
    "outputId": "3cd17a07-db60-4c34-a044-dd08df622538"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-27 02:59:23 INFO: Loading these models for language: ru (Russian):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | syntagrus |\n",
      "| pos       | syntagrus |\n",
      "| lemma     | syntagrus |\n",
      "=========================\n",
      "\n",
      "2021-12-27 02:59:23 INFO: Use device: cpu\n",
      "2021-12-27 02:59:23 INFO: Loading: tokenize\n",
      "2021-12-27 02:59:23 INFO: Loading: pos\n",
      "2021-12-27 02:59:24 INFO: Loading: lemma\n",
      "2021-12-27 02:59:25 INFO: Done loading processors!\n",
      "100%|██████████| 213/213 [01:34<00:00,  2.25it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "nlp = stanza.Pipeline('ru', processors='tokenize, pos, lemma')\n",
    "texts = []\n",
    "bios = []\n",
    "poses = []\n",
    "sentences = []\n",
    "train_sents = []\n",
    "lemmas = []\n",
    "sent_ids = []\n",
    "sent_id=0\n",
    "\n",
    "for text_id, text in tqdm(train_texts.values):\n",
    "    processed = nlp(text)\n",
    "    text_data = []\n",
    "    bio_data = []\n",
    "    lemma_data = []\n",
    "    pos_data = []\n",
    "    count_token = 0\n",
    "    for token in processed.iter_tokens():\n",
    "        add = False\n",
    "        for mention in train_asp[train_asp['text_id'] == text_id].values:\n",
    "            if token.start_char == int(mention[3]) and token.end_char <= int(mention[4]):\n",
    "                text_data.append(token.text)\n",
    "                lemma_data.append(token.words[0].lemma)\n",
    "                bio_data.append('B-'+mention[1])\n",
    "                pos_data.append(token.words[0].pos)\n",
    "                count_token += 1\n",
    "                add = True\n",
    "                sent_ids.append(sent_id)\n",
    "            elif token.start_char > int(mention[3]) and token.end_char <= int(mention[4]):\n",
    "                text_data.append(token.text)\n",
    "                lemma_data.append(token.words[0].lemma)\n",
    "                bio_data.append('I-'+mention[1])\n",
    "                pos_data.append(token.words[0].pos)\n",
    "                count_token += 1\n",
    "                add = True\n",
    "                sent_ids.append(sent_id)\n",
    "        if not add:\n",
    "            text_data.append(token.text)\n",
    "            lemma_data.append(token.words[0].lemma)\n",
    "            bio_data.append('O')\n",
    "            pos_data.append(token.words[0].pos)\n",
    "            count_token += 1\n",
    "            sent_ids.append(sent_id)\n",
    "    texts.extend(text_data)\n",
    "    lemmas.extend(lemma_data)\n",
    "    bios.extend(bio_data)\n",
    "    poses.extend(pos_data)\n",
    "    train_sents.append(list(zip(text_data, lemma_data, pos_data, bio_data)))\n",
    "    sentences.extend([f'Sentence: {sent_id}'] + ['']*(count_token - 1))\n",
    "    sent_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FpuwNojWwsZj",
    "outputId": "ebcdcdf8-637e-4135-8d27-424528a01bf9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-27 03:00:59 INFO: Loading these models for language: ru (Russian):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | syntagrus |\n",
      "| pos       | syntagrus |\n",
      "| lemma     | syntagrus |\n",
      "=========================\n",
      "\n",
      "2021-12-27 03:00:59 INFO: Use device: cpu\n",
      "2021-12-27 03:00:59 INFO: Loading: tokenize\n",
      "2021-12-27 03:01:00 INFO: Loading: pos\n",
      "2021-12-27 03:01:00 INFO: Loading: lemma\n",
      "2021-12-27 03:01:00 INFO: Done loading processors!\n",
      "100%|██████████| 71/71 [00:31<00:00,  2.23it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "nlp = stanza.Pipeline('ru', processors='tokenize, pos, lemma')\n",
    "texts = []\n",
    "bios = []\n",
    "poses = []\n",
    "sentences = []\n",
    "test_sents = []\n",
    "lemmas = []\n",
    "sent_ids = []\n",
    "sent_id=0\n",
    "\n",
    "for text_id, text in tqdm(test_texts.values):\n",
    "    processed = nlp(text)\n",
    "    text_data = []\n",
    "    bio_data = []\n",
    "    lemma_data = []\n",
    "    pos_data = []\n",
    "    count_token = 0\n",
    "    for token in processed.iter_tokens():\n",
    "        add = False\n",
    "        for mention in test_asp[test_asp['text_id'] == text_id].values:\n",
    "            if token.start_char == int(mention[3]) and token.end_char <= int(mention[4]):\n",
    "                text_data.append(token.text)\n",
    "                lemma_data.append(token.words[0].lemma)\n",
    "                bio_data.append('B-'+mention[1])\n",
    "                pos_data.append(token.words[0].pos)\n",
    "                count_token += 1\n",
    "                add = True\n",
    "                sent_ids.append(sent_id)\n",
    "            elif token.start_char > int(mention[3]) and token.end_char <= int(mention[4]):\n",
    "                text_data.append(token.text)\n",
    "                lemma_data.append(token.words[0].lemma)\n",
    "                bio_data.append('I-'+mention[1])\n",
    "                pos_data.append(token.words[0].pos)\n",
    "                count_token += 1\n",
    "                add = True\n",
    "                sent_ids.append(sent_id)\n",
    "        if not add:\n",
    "            text_data.append(token.text)\n",
    "            lemma_data.append(token.words[0].lemma)\n",
    "            bio_data.append('O')\n",
    "            pos_data.append(token.words[0].pos)\n",
    "            count_token += 1\n",
    "            sent_ids.append(sent_id)\n",
    "    texts.extend(text_data)\n",
    "    lemmas.extend(lemma_data)\n",
    "    bios.extend(bio_data)\n",
    "    poses.extend(pos_data)\n",
    "    test_sents.append(list(zip(text_data, lemma_data, pos_data, bio_data)))\n",
    "    sentences.extend([f'Sentence: {sent_id}'] + ['']*(count_token - 1))\n",
    "    sent_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "IbULggxQc9GL"
   },
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    lemma = sent[i][1]\n",
    "    postag = sent[i][2]\n",
    "    tfvec = vectorizer.transform([lemma])\n",
    "    if lemma + '_' + postag in model:\n",
    "        w2vec = model[lemma + '_' + postag]\n",
    "    else:\n",
    "        w2vec= np.zeros((300,))\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'postag=' + postag,\n",
    "        'lemma=' + lemma,\n",
    "        'w2v=%s' % w2vec,\n",
    "        'tfvec=%s' % tfvec,\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        lemma1 = sent[i-1][1]\n",
    "        postag1 = sent[i-1][2]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:postag=' + postag1,\n",
    "            '-1:lemma=' + lemma,\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "  \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        lemma1 = sent[i+1][1]\n",
    "        postag1 = sent[i+1][2]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:postag=' + postag1,\n",
    "            '+1:lemma=' + lemma,\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, lemma, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, lemma, postag, label in sent] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "pQOuMmjdtKi2"
   },
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VvABrVY50EmJ",
    "outputId": "48441e3c-0c73-4ea7-8d04-12eac2631bd5"
   },
   "outputs": [],
   "source": [
    "def bio_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "RH3wb6NayGO-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-27 04:13:53 INFO: Loading these models for language: ru (Russian):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | syntagrus |\n",
      "=========================\n",
      "\n",
      "2021-12-27 04:13:53 INFO: Use device: cpu\n",
      "2021-12-27 04:13:53 INFO: Loading: tokenize\n",
      "2021-12-27 04:13:53 INFO: Done loading processors!\n",
      "/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-Food       0.76      0.65      0.70       449\n",
      "      I-Food       0.78      0.58      0.67       273\n",
      "  B-Interior       0.90      0.54      0.68       176\n",
      "  I-Interior       0.53      0.34      0.42        29\n",
      "     B-Price       0.79      0.56      0.66        34\n",
      "     I-Price       0.00      0.00      0.00        11\n",
      "   B-Service       0.91      0.63      0.75       338\n",
      "   I-Service       0.75      0.49      0.59        74\n",
      "     B-Whole       0.80      0.74      0.77       185\n",
      "     I-Whole       0.75      0.31      0.44        48\n",
      "\n",
      "   micro avg       0.81      0.60      0.69      1617\n",
      "   macro avg       0.70      0.48      0.57      1617\n",
      "weighted avg       0.80      0.60      0.69      1617\n",
      " samples avg       0.08      0.08      0.08      1617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-Food       0.75      0.67      0.71       449\n",
      "      I-Food       0.80      0.59      0.68       273\n",
      "  B-Interior       0.90      0.54      0.68       176\n",
      "  I-Interior       0.50      0.34      0.41        29\n",
      "     B-Price       0.78      0.53      0.63        34\n",
      "     I-Price       0.00      0.00      0.00        11\n",
      "   B-Service       0.89      0.65      0.75       338\n",
      "   I-Service       0.61      0.51      0.56        74\n",
      "     B-Whole       0.80      0.78      0.79       185\n",
      "     I-Whole       0.77      0.35      0.49        48\n",
      "\n",
      "   micro avg       0.80      0.62      0.70      1617\n",
      "   macro avg       0.68      0.50      0.57      1617\n",
      "weighted avg       0.80      0.62      0.69      1617\n",
      " samples avg       0.08      0.08      0.08      1617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-Food       0.73      0.67      0.70       449\n",
      "      I-Food       0.83      0.49      0.62       273\n",
      "  B-Interior       0.86      0.60      0.71       176\n",
      "  I-Interior       0.59      0.34      0.43        29\n",
      "     B-Price       0.81      0.65      0.72        34\n",
      "     I-Price       0.00      0.00      0.00        11\n",
      "   B-Service       0.87      0.65      0.75       338\n",
      "   I-Service       0.80      0.43      0.56        74\n",
      "     B-Whole       0.77      0.74      0.76       185\n",
      "     I-Whole       0.71      0.35      0.47        48\n",
      "\n",
      "   micro avg       0.80      0.61      0.69      1617\n",
      "   macro avg       0.70      0.49      0.57      1617\n",
      "weighted avg       0.79      0.61      0.68      1617\n",
      " samples avg       0.08      0.08      0.08      1617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-Food       0.73      0.71      0.72       449\n",
      "      I-Food       0.81      0.53      0.64       273\n",
      "  B-Interior       0.85      0.64      0.73       176\n",
      "  I-Interior       0.58      0.52      0.55        29\n",
      "     B-Price       0.79      0.68      0.73        34\n",
      "     I-Price       0.00      0.00      0.00        11\n",
      "   B-Service       0.84      0.68      0.75       338\n",
      "   I-Service       0.74      0.47      0.58        74\n",
      "     B-Whole       0.76      0.77      0.77       185\n",
      "     I-Whole       0.75      0.38      0.50        48\n",
      "\n",
      "   micro avg       0.78      0.64      0.70      1617\n",
      "   macro avg       0.68      0.54      0.60      1617\n",
      "weighted avg       0.78      0.64      0.70      1617\n",
      " samples avg       0.09      0.09      0.09      1617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/marynepo/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-Food       0.62      0.67      0.64       449\n",
      "      I-Food       0.71      0.46      0.56       273\n",
      "  B-Interior       0.77      0.56      0.65       176\n",
      "  I-Interior       0.45      0.48      0.47        29\n",
      "     B-Price       0.71      0.59      0.65        34\n",
      "     I-Price       0.00      0.00      0.00        11\n",
      "   B-Service       0.67      0.64      0.65       338\n",
      "   I-Service       0.49      0.31      0.38        74\n",
      "     B-Whole       0.70      0.67      0.68       185\n",
      "     I-Whole       0.46      0.23      0.31        48\n",
      "\n",
      "   micro avg       0.65      0.58      0.61      1617\n",
      "   macro avg       0.56      0.46      0.50      1617\n",
      "weighted avg       0.65      0.58      0.61      1617\n",
      " samples avg       0.08      0.08      0.08      1617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "\n",
    "nlp = stanza.Pipeline('ru', processors='tokenize')\n",
    "\n",
    "algs = ['lbfgs', 'l2sgd', 'ap', 'pa', 'arow']\n",
    "for i, alg in enumerate(algs):\n",
    "    trainer = pycrfsuite.Trainer(algorithm=alg, verbose=False)\n",
    "\n",
    "    for xseq, yseq in zip(X_train, y_train):\n",
    "        trainer.append(xseq, yseq)\n",
    "    '''trainer.set_params({\n",
    "        'c1': 1.0,   # coefficient for L1 penalty\n",
    "        'c2': 1e-3,  # coefficient for L2 penalty\n",
    "        'max_iterations': 50,  # stop earlier\n",
    "\n",
    "        # include transitions that are possible, but not observed\n",
    "        'feature.possible_transitions': True\n",
    "    })'''\n",
    "\n",
    "    trainer.train('restaurants.crfsuite')\n",
    "    tagger = pycrfsuite.Tagger()\n",
    "    tagger.open('restaurants.crfsuite')\n",
    "    y_pred = [tagger.tag(xseq) for xseq in X_test]\n",
    "    print(bio_classification_report(y_test, y_pred))\n",
    "\n",
    "    tids = []\n",
    "    mentions = []\n",
    "    cats = []\n",
    "    starts = []\n",
    "    ends = []\n",
    "    for texts, ss, pred, fd, interior in zip(test_texts.values, test_sents, y_pred, foods, intrs):\n",
    "        text = list(nlp(texts[1]).iter_tokens())\n",
    "        ment = []\n",
    "        for i, ss in enumerate(zip(text, pred)):\n",
    "            token = ss[0]\n",
    "            tg = ss[1]\n",
    "            if tg != 'O':\n",
    "                ment.append(token.text)\n",
    "                cat = tg[2:]\n",
    "                if tg[:2] == 'B-':\n",
    "                    st = token.start_char\n",
    "                if i + 1 != len(pred):\n",
    "                    if pred[i+1][:2] != 'I-':\n",
    "                        en = token.end_char\n",
    "                        mentions.append(ment)\n",
    "                        tids.append(texts[0])\n",
    "                    #print(i, en, token, tg, pred[i+1], pred[i-1])\n",
    "                        starts.append(st)\n",
    "                        ends.append(en)\n",
    "                        cats.append(cat)\n",
    "\n",
    "                        with open(f'pred_asp_{alg}_dict.txt', 'a') as f:\n",
    "                            print(texts[0], cat, texts[1][st:en], st, en, 'positive', sep='\\t', file=f)\n",
    "                        ment = []\n",
    "                else:\n",
    "                    en = token.end_char\n",
    "                    mentions.append(ment)\n",
    "                    tids.append(texts[0])\n",
    "                    starts.append(st)\n",
    "                    ends.append(en)\n",
    "                    cats.append(cat)\n",
    "                    with open(f'pred_asp_{alg}_dict.txt', 'a') as f:\n",
    "                        print(texts[0], cat, texts[1][st:en], st, en, 'positive', sep='\\t', file=f)\n",
    "                    ment = []\n",
    "            elif (token.text, token.start_char, token.end_char) in fd:\n",
    "                with open(f'pred_asp_{alg}_dict.txt', 'a') as f:\n",
    "                        print(texts[0], 'B-Food', token.text, token.start_char, token.end_char, 'positive', sep='\\t', file=f)\n",
    "            elif (token.text, token.start_char, token.end_char) in interior:\n",
    "                with open(f'pred_asp_{alg}_dict.txt', 'a') as f:\n",
    "                        print(texts[0], 'B-Interior', token.text, token.start_char, token.end_char, 'positive', sep='\\t', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Baselines.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1772388bcbb9481596c7f61c4b57a319": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24e1ddb189c241efb10fe2ae09ff6f96": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32c26bce5567415cac8dcf9ff296bcbc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b7b7d270cbc44da92974d964cd14fc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "54064900512946a19040cca9a7b82e68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e0fdf9b289a847f5b1a150faacc20ade",
       "IPY_MODEL_8531cde142584324b212b7a509f47be4",
       "IPY_MODEL_58557af4f4324953ab21ebf6a6bae77c"
      ],
      "layout": "IPY_MODEL_79453b158d684585a15ada1fa853caba"
     }
    },
    "58557af4f4324953ab21ebf6a6bae77c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7024e1a9fc0e4d3a8c78f191f2f3d926",
      "placeholder": "​",
      "style": "IPY_MODEL_81db27d8ef1842509c248b404849d436",
      "value": " 142k/? [00:00&lt;00:00, 3.51MB/s]"
     }
    },
    "5b5ced37b48c4a2480ce9c327eb6e2d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae430dfc37294e588bb1301b81aabfa6",
      "placeholder": "​",
      "style": "IPY_MODEL_3b7b7d270cbc44da92974d964cd14fc5",
      "value": " 574M/574M [00:05&lt;00:00, 109MB/s]"
     }
    },
    "5ebb4cb43ba34eea92fdb030cf7f6afd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5fd9bbd673344886840007fdd22ad0c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "652b46a7dbef47aca6032f67a1c98256": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24e1ddb189c241efb10fe2ae09ff6f96",
      "max": 574067219,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5fd9bbd673344886840007fdd22ad0c0",
      "value": 574067219
     }
    },
    "7024e1a9fc0e4d3a8c78f191f2f3d926": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79453b158d684585a15ada1fa853caba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7dddf865418f45cd8ad98b89e2dcd5ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ebb4cb43ba34eea92fdb030cf7f6afd",
      "placeholder": "​",
      "style": "IPY_MODEL_a394d8b703a14a759f33d9eee8dc8c5a",
      "value": "Downloading https://huggingface.co/stanfordnlp/stanza-ru/resolve/v1.3.0/models/default.zip: 100%"
     }
    },
    "81db27d8ef1842509c248b404849d436": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8531cde142584324b212b7a509f47be4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac5e7c14666f476e802cca24bd1ca59e",
      "max": 24459,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d397546a7708495c929a68b786586779",
      "value": 24459
     }
    },
    "a394d8b703a14a759f33d9eee8dc8c5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ac5e7c14666f476e802cca24bd1ca59e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae430dfc37294e588bb1301b81aabfa6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d31990b02c4d40c2961776b303a7fb0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d397546a7708495c929a68b786586779": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d7658cd04b984486af4cde6763fbe847": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7dddf865418f45cd8ad98b89e2dcd5ab",
       "IPY_MODEL_652b46a7dbef47aca6032f67a1c98256",
       "IPY_MODEL_5b5ced37b48c4a2480ce9c327eb6e2d7"
      ],
      "layout": "IPY_MODEL_32c26bce5567415cac8dcf9ff296bcbc"
     }
    },
    "e0fdf9b289a847f5b1a150faacc20ade": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1772388bcbb9481596c7f61c4b57a319",
      "placeholder": "​",
      "style": "IPY_MODEL_d31990b02c4d40c2961776b303a7fb0d",
      "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json: "
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
